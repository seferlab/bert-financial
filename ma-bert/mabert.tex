\documentclass[11pt]{article}

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

\usepackage{url}
\usepackage{chapterbib}
\usepackage[sectionbib]{natbib}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{array}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


\title{MergerBERT: Predicting Merger Targets and Acquirers from Text via Pretrained Language Models}
\author{}
\date{}

% Candidate Journals
% Quantitative Finance UYGUN LATEX VAR
% Review of Financial Studies
% Review of Finance UYGUN Latex var
% Mathematical Finance UYGUN latex yok
%Journal of Financial and Quantitative Analysis -> non refundable fee
%Finance Research Letters -> non refundable fee
%Review of Quantitative Finance and Accounting UYGUN LATEX VAR
% Journal of Corporate Finance non refundable fee
% The review of corporate finance studies UYGUN Latex var

\begin{document}

\maketitle

We explore the use of a U.S.firm's SEC filings to predict whether the firm will be
an acquirer or a target of an acquisition within a year of the
filing. Our approach uses transfer learning.

%Our approach uses text regression, in which frequencies of words and phrases in the document are used as
%independent variables in a logistic regression model.
We find that word and phrase features have significant predictive power in models of being an acquirer or a target. In each case, the
best performing models involve a different use of text alongside
standard financial variables.

We apply the proposed model on several real-world tasks and achieve
state-of-the-art performance in almost all of cases.

While research on merger and acquisition (M&A) has been extensive in the finance literature, in the realm of data science, little work has been done on deploying a successful Big Data informed M&A prediction model. In this paper, we explore what can be learned about M&A activity from a firm's annual Form 10-K SEC filing. We utilize natural language processing (NLP) techniques to vectorize each filing's textual data. Next, we cluster firms by industry and identify keywords suggestive of upcoming M&A activity. We then train a classifier to predict acquirers and targets, which we use to forecast the most likely M&As of 2019. Lastly, we deploy an application which enables users to query our forecasts and visualize our data.


\section{Introduction}

Our perform outperforms all other methods.
Single text classification

%additional knowledge
Between 2000 and 2018, more than $790000$ transactions have been announced
worldwide with a known value of over $57$ trillion USD. In 2018, the
number of deals has decreased by $8\%$ to about $49000$ transactions,
while their value has increased by $4\%$ to $3.8$ trillion USD.

% Mergers
Mergers and acquisitions (M\&As) play a key role in the economy. At the aggregate level,
M\&A transactions represent the main mechanism for consolidation and restructuring within
industries, and their value as a fraction of U.S. GDP is substantial
($5.8\%$ between 1980 and 2011)~\cite{routledge2013}. At the individual company level, takeovers constitute major investment decisions and
an effective way to discipline inefficient managers. Given their importance in the economy, it
is no surprise that merger and acquisitions have attracted a great
deal of attention among researchers. As a result, there is a wide body of theoretical and empirical research surrounding
mergers~\cite{xxx}.

%general info about mergers 
Mergers are important, but they are also a relatively infrequent
event. For instance, an average of about $5\%$ of public firms have been acquired every year between 1980
and 2011~\cite{routledge2013}~(This is the average fraction of firms that are dropped from the Center for Research in Security Prices
(CRSP) sample during a year because they are acquired). Interestingly, but perhaps not surprisingly, mergers are
difficult to predict. In the prior research aimed at predicting targets, the general conclusion is
that predicting target firms with any accuracy has proven to be
difficult~\cite{betton2008}. The explanatory power of the models is
relatively low, with some evidence of interesting time-series properties (mergers come in waves).

%Merger importance
More directly, mergers are important from many perspectives. Merger announcements typically involve a large premium over
current prices (between $40\%$ and $50\%$ on average see~\cite{eckbo2014}) and lead to a large and
rapid change in market prices suggesting the announcement is news to
the market. Not coincidentally, many insider trading cases involve suspicious trades of insiders around the date
of a merger announcement~\cite{keown1981}. Accordingly, any improvement in the ability to predict which firms will be involved in a merger deal
would prove to be very profitable for an investor in the stock market.

% BERT
Pretrained models have recently been

Recently, unsupervised pre-training of language models on large corpora has significantly improved
the performance of many NLP tasks. The language models are pretained on generic corpora
such as Wikipedia. However, sentiment analysis
is a strongly domain dependent task. Financial
sector has accumulated large scale of text of financial
and business communications. Therefore,
leveraging the success of unsupervised pretraining
and large amount of financial text could potentially
benefit wide range of financial applications.

One of such application is merger target and acquirer prediction.

NLP transfer learning methods look like a promising solution
to both of the challenges mentioned above, and are the focus of
this thesis. The core idea behind these models is that by training
language models on very large corpora and then initializing
down-stream models with the weights learned from the language
modeling task, a much better performance can be achieved. The
initialized layers can range from the single word embedding layer
[23] to the whole model [5]. This approach should, in theory, be an
answer to the scarcity of labeled data problem. Language models
don’t require any labels, since the task is predicting the next word.
They can learn how to represent the semantic information. That
leaves the fine-tuning on labeled data only the task of learning how
to use this semantic information to predict the labels.

One particular component of the transfer learning methods is the
ability to further pre-train the language models on domain specific
unlabeled corpus. Thus, the model can learn the semantic relations
in the text of the target domain, which is likely to have a different
distribution than a general corpus. This approach is especially
promising for a niche domain like finance, since the language



% what we do
In this paper, we predict whether a firm will participate in a merger or acquisition either as an acquirer or a target by exploiting
text data. Specifically, we focus on U.S. firms, and use the disclosure in the firm's Management
Discussion and Analysis (MD\&A) section of the annual 10-K
filing form. We consider two types of predictions: 1) Will the firm be an acquirer in the subsequent year after the filing? and 2) Will the firm
be the target of an acquisition in the subsequent year? We explore the quality of text
in making these predictions, and demonstrate how text-based prediction models can offer
intuitive hints about upcoming mergers.

The central contributions of this paper are as follows:

\begin{itemize}
\item We introduce MergerBERT, which is based on pretrained language model based
  on BERT for target and acquirer prediction in mergers. We evaluate
  the effectiveness of MergerBERT on historical 10-K and Merger and
  Acquisition~(M\&A) datasets. MergerBERT models innovations for scalable text-driven forecasting.
\item We achieve the state-of-the-art results on both target and
  acquirer prediction via pretrained models in MergerBERT. Our results demonstrate the predictive utility of text disclosures for
  takeover bids. MergerBERT achieves $xxx\%$ and $yyy\%$ better performance than
  baseline approach in acquirer and target prediction respectively.
\item We conduct experiments to investigate several aspects of
  the model, including: effects of further pre-training on financial
corpus, training strategies to prevent catastrophic
forgetting and fine-tuning only a small subset of model layers
for decreasing training time without a significant drop
in performance.
\end{itemize}

%papers contribution 
This paper contributes to the literature that studies the determinants of corporate
acquisition decisions. To the best of our knowledge, this is the first paper that uses pretrained models to predict takeover targets and
acquirers.

\subsection{Related Work}

~\cite{hoberg2010} uses variables constructed from text to predict M\&A events. However, their approach is substantially different from ours: They build measures of product market similarity across
firms from 10-K product descriptions, and employ them as explanatory variables in standard
logistic regressions to predict targets and acquirers.~\cite{routledge2013} uses text regressions to study the predictive power of words and phrases used by the management in their annual
10-K discussion and analysis for takeover events. In comparison, our proposed method MergerBERT is different than these methods in
multiple ways: 1-Our method is , 2-yyy.

% text to study corporate finance decisions
In general, we contribute to the growing literature that uses data extracted from
text to study corporate finance decisions.~\cite{loughran2013,jegadeesh2013} perform textual analyses of the initial public offering prospectuses to study stock
returns of IPO firms.~\cite{hoberg2015,bodnaruk2015,Buehlmaier2015} generate text-based measures of financial constraints
to study corporate investment, financing decisions, and stock returns, respectively.
Our paper shows that information from text when combined with recent deep learning methods is useful to predict mergers and acquisitions,
which represent one of the most important investment decisions that firms undertake.

The paper is organized as follows: Section 2 describes the data and the
construction of the financial and text variables used for estimation. Section 3 presents the estimation methodology,
Section 4 the baseline regression results using standard financial variables, and Section 5
the results incorporating text variables. Section 6 develops and estimates a predictive model
that interacts financial and text variables, and Section 7 concludes.

\section{Experiments}

\subsection{Financial Model Baseline}

Our baseline is logistic regression model with financial explanatory variables. This baseline model uses explanatory
variables that are standard in the literature as in Table~\ref{tab:financial}. For each of
the variables in Table~\ref{tab:financial}, we transform them with the
z-score to ease interpretation. We use an indicator variable for each calendar
year (the year is the year the report is published: 1995 - 2011). Financial variables are all
measured for the year-end of the 10-K report.

For our resulting model with intercept, we estimate both an regularized and unregularized laogistic regression models. The
regularized and unregularized results are shown in~\ref{tab:baseline_results}. Results
between regularized and unregularized models are almost indistinguishable in performance, where coefficients
are also similar.

For the acquirer prediction task, we achieve a pseudo $R^{2}$ just below $0.07$, with the year
and firm size as the strongest effects. For the target prediction task, we find that this
model obtains a pseudo $R^{2}$ of $0.0262$. This baseline is comparable to, and perhaps stronger than,
the values reported by two other studies with overlapping data~\cite{cremers2008, edmans2012}. According to our results, xxx, yyy, and zzz are
significant predictors. Overall, these experiments suggest that the target task is more difficult than the acquirer task.

\begin{table}
  \begin{tabular}{|c|c|}
    \hline
Tobin's Q~\cite{xxxx} & The ratio of the market value of company's equity value to book \\ \hline
PPE & The book value of property plant and equipment \\ \hline
Cash balance & Logarithm \\ \hline
Size of Leverage & Book value of debt over book value of assets \\ \hline
Size & Market value of equity \\ \hline
Return on Assets & Operating income divided by year-end book value of
                   assets \\ \hline
  \end{tabular}
  \label{tab:financial}
  \caption{}
\end{table}

\begin{table}
  \begin{tabular}{|c|c|}
  \end{tabular}
  \label{tab:baseline_results}
  \caption{
The regularized and unregularized maximum likelihood estimates for the
baseline logistic regression model, and performance on test (out of
sample) data. For regularized estimate, $\lambda_{1} = xxx$ and
$\lambda_{2} = xxx$. Table shows only the strongest positive-weighted and negative-weighted
year coefficient for each model.}
\end{table}


\section{Data}

This research is based on three kinds of data: Financial disclosures via
company 10-K filings, company financial data, and M\&A events.

% One results will be only on successfull offer. Another one will be
% over the ones with unsuccesful offers.

% One result will be on BERT without financial domain training. The
% other will be on BERT with financial domain training.

\subsection{Merger Bid Event Data}

Our data is obtained from Eikon Thomson Reuters database. We focus on
the list of company pairs that have made~(acquirer) and received~(target) a merger offer in a given year from Eikon
database. Such offers may eventually be unsuccessful or successful. Each offer occurs on a specific date, and we focus on the period
1995-2019 which overlaps with our disclosure 10-K dataset in
Section~\ref{sec:10k}. We drop cases in which the bidder already owns more than $50\%$ of the target shares prior to
the announcement of the bid, in order to exclude acquisitions of
minority interest in the target or stock repurchases. We also drop a bid if either of the following conditions are
satisfied: 1- The percentage of shares that the bidder is seeking to acquire is less than $50\%$ of the target shares, 2- If
such percentage information is missing, and 3- If the fraction of shares held by the bidder after a completed
transaction is less than $50\%$. We also drop observations that SDC labels as block purchases, creeping
acquisition, privatization.

This definition of a takeover is standard in the literature (see Betton, Eckbo, and Thorburn, 2008).
Over 1995-2019 period, we have $xxx$ takeover bids. However, many of these takeover bids involve non-US or private that do
not file 10-K with the US Securities and Exchange Commission
(SEC). There are only $xxx$ takeovers where at least one of the parties
(target or acquirer) is public. Lastly, we focus on transactions where we have
both financial data (via Compustat) and text data (via the 10-K annual reports) so that
we can fairly compare our text model with existing studies and
baseline approach purely on financial data. The final size of the data is
summarized in Table~\ref{tab:summary_stats}.

\begin{table}
  \begin{tabular}{L{4cm} L{3cm} L{3cm} L{3cm}}
    \hline 
Datasets & Number of Firm-Year Observations & Number of  Acquirers
    &Number of Targets \\ \hline
Training (for parameter estimation) & & & \\ \hline
Development (for hyperparameter tuning) & & & \\ \hline
    Test (for measuring $R^{2}$)   & & & \\
    \hline
  \end{tabular}
  \label{tab:summary_stats}
  \caption{Summary of datasets used in this research}
\end{table}

\subsection{Financial Data}\label{sec:financial}

The financial data is from Compustat. The specific explanatory variables we use are the
usual and standard ones in this literature: Tobin's Q (ratio of the
market value of company assets to book value), PPE (the book value of
property plant and equipment), log of cash balance, the size of leverage (book value of debt over book value of assets), size (market value
of equity) and return on assets (operating income divided by year-end book value of assets).
For ease of interpretation we standardize these variables to have mean $0$ and variance $1$.

\subsection{Form 10-K Text Corpus}\label{sec:10k}

Our text data comes from the annual report, the Form 10-K that each
publicly company files with the SEC. Inside the 10-K is a section
called Management's Discussion and Analysis (MD\&A). The MD\&A section
is where management reviews the past year's financial and other
results and discusses forecasts of the future. Using MD\&A section is in line with previous work~\cite{routledge2013}.

From $1995$ to $2019$ we have $xxx$ firm-year
observations.

The text was processed similar to many studies that use text as a regressor. Punctuation
was removed and all words were down-cased. Numerical, percentage, and dollar figures were
replaced with a token. For example, $50,000$ and $2.00$ are both replaced by $\#$ (recall
that we have high quality financial information from the Compustat data). These individual
words (and tokens) are called unigrams. To capture multiple word chains, we constructed
multiword phrases from our data. Phrases are identified by applying a program that identifies each word's part of speech,8 then conjoins common phrase patterns (adjective-noun,
for example). Common phrases include: 'financial condition', 'capital resources', 'common
stock', 'qualitative disclosures', 'market risk', 'fair value', and 'financial statements.' Combined,
there are 236,480 unigrams and phrases in our ''training" data; as described below.
We discard features that are used less than 500 times and in less than 200 documents.
This leaves 12,243 unique terms. Let freq(j; n) denote the frequency
of the jth term type in the $n$th document. Since these counts are highly skewed, we log-transform them. Our
right-hand-side textual independent variables are $xn;j = \log (1 + freq(j; n))$.




% Merging datasets



% Using Machine Learning to Analyze Merger Activity
In this paper, I use machine learning techniques in order to use a new dataset to analyze
merger activity - a firm’s annual 10K SEC statements. This 10K statement contains description
about firm and firm products that will capture difficult to observe
variables that could perform quite well with explaining mergers.

I find that the lasso and the ridge regularization techniques have found not only words that align with previous merger theory, but also some interesting
variables that were not previously considered. Using this new technique, I obtained a predictive
model that yields an R-squared that ranges from $0.02$ to $0.07$.

% Product Market Synergies and Competition in Mergers and
% Acquisitions: A Text Based Analysis
~\cite{hoberg2010}
We examine how product similarity and competition influence mergers and
acquisitions and the ability of firms to exploit product market synergies through
asset complementarities. Using novel text-based analysis of firm 10K product
descriptions, we find three key results. 1) Firms are more likely to enter
mergers with firms whose language describing their assets is similar. 2) Transactions in competitive product markets with similar acquirer and target firms
experience increased stock returns and real longer-term gains in cash flows and
higher growth in their product descriptions. 3) These gains are higher when
the target is less similar to the acquirer’s closest rivals, and when firms have the
potential for unique products. Our findings are consistent with firms merging
and buying assets to exploit asset complementarities and to create new
products to increase product differentiation.

Our analysis is two-fold. We apply modified BERT to financial text
prediction. We also present analysis similar to ~\cite{moriarty2019}.




\section{Introduction}


This result is in line with the Q-theory of mergers and acquisitions~\cite{jovanovic2002}, which
predicts that profitable companies are eager to acquire poor-performing firms and generate
operational gains by putting their assets to a more productive use.


~\cite{katsafados2019}


~\cite{katsafados2020}
%Textual information and IPO underpricing: A machine learning approach
This study examines the predictive power of textual information from S-1 filings in
explaining IPO underpricing. Our empirical approach differs from previous research, as we
utilize several machine learning algorithms to predict whether an IPO will be underpriced, or
not. We analyze a large sample of 2,481 U.S. IPOs from 1997 to 2016, and we find that
textual information can effectively complement traditional financial variables in terms of
prediction accuracy. In fact, models that use both textual data and financial variables as
inputs have superior performance compared to models using a single type of input. We
attribute our findings to the fact that textual information can reduce the ex-ante valuation
uncertainty of IPO firms, thus leading to more accurate estimates.

~\cite{routledge2013}

~\cite{linlin2018}


Mergers and acquisitions (M\&As) play a key role in the economy. At the aggregate level,
M\&A transactions represent the main mechanism for consolidation and restructuring within
industries, and their value as a fraction of U.S. GDP is substantial; $5.8\%$ between $1980$ and
$2011$ (according to M\&A volume is computed from SDC Platinum data as the aggregate value of completed acquisitions of
U.S. target companies). At the individual company level, takeovers constitute major investment decisions and
an effective way to discipline ineffcient managers. Given their importance in the economy, it
is no surprise that M\&As have attracted a great deal of attention among researchers|there
is a wide body of theoretical and empirical research surrounding
mergers.


\subsection{Related Work}


Using textual analysis to identify merger participants: Evidence from the U.S. banking industry~\cite{xxx}.

Confining value from neural networks
A sectoral study prediction of takeover targets
in the US technology sector


Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP)
tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word
representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been
widely demonstrated for English using contextualized representations~\cite{dai2015, peters2018, howard2018, radford2018, devlin2019, yang2019}.

%GPT2 Paper
Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically
approached with supervised learning on task specific datasets. We demonstrate that language
models begin to learn these tasks without any explicit supervision when trained on a new dataset
of millions of webpages called WebText. When
conditioned on a document plus questions, the answers generated by the language model reach 55
F1 on the CoQA dataset - matching or exceeding
the performance of 3 out of 4 baseline systems
without using the 127,000+ training examples.
The capacity of the language model is essential
to the success of zero-shot task transfer and increasing it improves performance in a log-linear
fashion across tasks. Our largest model, GPT-2,
is a 1.5B parameter Transformer that achieves
state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting
but still underfits WebText. Samples from the
model reflect these improvements and contain coherent paragraphs of text. These findings suggest
a promising path towards building language processing systems which learn to perform tasks from
their naturally occurring demonstrations~\cite{radford2019} 

%related work
There are previous methods that use Machine learning to predict stock
markets.~\cite{ding2015} proposes a deep learning method for
event-driven stock market prediction. First, events are extracted from news text, and represented as dense vectors,
trained using a novel neural tensor network. Second, a deep convolutional neural network is used to model both short-term and
long-term influences of events on stock price movements.

The use of robo-readers to analyze news texts is an emerging technology trend in computational finance. In recent
research, a substantial effort has been invested to develop sophisticated financial polarity-lexicons that can be used to
investigate how financial sentiments relate to future company performance. However, based on experience from other
fields, where sentiment analysis is commonly applied, it is well-known
that the overall semantic orientation of a sentence may differ from
the prior polarity of individual words.

% Neural network model
Financial risk, defined as the chance to deviate from return expectations, is most commonly measured
with volatility. Due to its value for investment decision making, volatility prediction is probably
among the most important tasks in finance and risk management. Although evidence exists that enriching purely financial models with natural language
information can improve predictions of volatility, this task is still comparably underexplored. We introduce PRoFET, the
first neural model for volatility prediction jointly exploiting both
semantic language representations and a comprehensive set of financial
features. As language data, we use transcripts from quarterly
recurring events, so-called earnings calls; in these calls, the performance of publicly traded companies is summarized and prognosticated by their management. We show that our
proposed architecture, which models verbal context with an attention mechanism, significantly outperforms the previous state-of-the-art and other strong
baselines. Finally, we visualize this attention mechanism on the token-level, thus aiding interpretability and providing a use case of PRoFET as a tool
for investment decision support~\cite{theil2019}.


\bibliographystyle{plain}
\bibliography{mabert}


\end{document}
